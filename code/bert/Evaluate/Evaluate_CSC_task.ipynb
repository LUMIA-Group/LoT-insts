{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate BERT for CSC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import pickle\r\n",
    "import torch.nn as nn\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\r\n",
    "from transformers import Trainer, TrainingArguments\r\n",
    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification\r\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\r\n",
    "from utils.data_helper import read_mag_file\r\n",
    "from utils.lazydataset import LazyTextMAG_Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "save_pkl_root = '/home/datamerge/ACL/Data/210422/pkl/'\r\n",
    "save_train_root = '/home/datamerge/ACL/Data/210422/train/'\r\n",
    "save_test_root = '/home/datamerge/ACL/Data/210422/test/'\r\n",
    "save_open_root = '/home/datamerge/ACL/Data/210422/open/'\r\n",
    "save_dev_root = '/home/datamerge/ACL/Data/210422/dev/'\r\n",
    "\r\n",
    "afid2nor = pickle.load(open(save_pkl_root+\"afid2nor.pkl\", \"rb\"))\r\n",
    "nor2afid = pickle.load(open(save_pkl_root+\"nor2afid.pkl\", \"rb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nor2len_dict = pickle.load(open(save_pkl_root+'210422_nor2len_dict.pkl', 'rb'))\r\n",
    "\r\n",
    "train_mid2label_dict = pickle.load(open(save_pkl_root+'train_mid2label_dict.pkl', 'rb'))\r\n",
    "train_label2mid_dict = pickle.load(open(save_pkl_root+'train_label2mid_dict.pkl', 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_filepath = save_train_root+'train_part.txt'\r\n",
    "dev_filepath = save_dev_root+'dev.txt'\r\n",
    "test_filepath = save_test_root+'test.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\r\n",
    "\r\n",
    "dev_dataset = LazyTextMAG_Dataset(tokenizer, dev_filepath, train_label2mid_dict)\r\n",
    "test_dataset = LazyTextMAG_Dataset(tokenizer, test_filepath, train_label2mid_dict)\r\n",
    "\r\n",
    "# dev_dataset = LazyTextMAG_Dataset(tokenizer, dev_filepath, train_label2mid_dict, block_size=64)\r\n",
    "# test_dataset = LazyTextMAG_Dataset(tokenizer, test_filepath, train_label2mid_dict, block_size=64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\r\n",
    "\r\n",
    "class BertForAffiliationNameNormalization(torch.nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self, num_of_classes):\r\n",
    "        super(BertForAffiliationNameNormalization, self).__init__()\r\n",
    "        self.num_of_classes = num_of_classes\r\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased').to(device)\r\n",
    "        self.dropout = nn.Dropout(p=0.1, inplace=False).to(device)\r\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, self.num_of_classes, bias=True).to(device)\r\n",
    "        \r\n",
    "        \r\n",
    "    def forward(self, input_ids, attention_mask):\r\n",
    "        pooled_out = self.bert(input_ids, attention_mask=attention_mask)\r\n",
    "        pooled_out = self.dropout(pooled_out[1])\r\n",
    "        logits = self.classifier(pooled_out)\r\n",
    "        \r\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = torch.load('./checkpoint0422/After_epoch_79_bert.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def report(true, pred):\r\n",
    "    all_labels = list(set(true))\r\n",
    "    a = accuracy_score(true, pred) * 100\r\n",
    "    p = precision_score(true, pred, average=\"macro\", labels=all_labels, zero_division=0) * 100\r\n",
    "    r = recall_score(true, pred, average=\"macro\", labels=all_labels) * 100\r\n",
    "    f = f1_score(true, pred, average=\"macro\", labels=all_labels, zero_division=0) * 100\r\n",
    "    return a, p, r, f\r\n",
    "\r\n",
    "\r\n",
    "def calc_split(low_margin, high_margin, true, pred, test_set_size):\r\n",
    "    low = test_set_size < low_margin\r\n",
    "    high = test_set_size > high_margin\r\n",
    "    mid = np.logical_and(test_set_size >= low_margin, test_set_size <= high_margin)\r\n",
    "\r\n",
    "    r1 = report(true[high], pred[high])\r\n",
    "    r2 = report(true[mid], pred[mid])\r\n",
    "    r3 = report(true[low], pred[low])\r\n",
    "    \r\n",
    "    return r1, r2, r3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def evaluate_test(model, dataset, nor2len_dict, train_mid2label_dict):\r\n",
    "    model.eval()\r\n",
    "    device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\r\n",
    "#     model = nn.DataParallel(model, device_ids=[0,1,2,3])\r\n",
    "#     model.to(torch.device('cuda:1'))\r\n",
    "    \r\n",
    "    test_dataset = dataset\r\n",
    "    loader = torch.utils.data.DataLoader(test_dataset, batch_size=128)\r\n",
    "    true = []\r\n",
    "    pred = []\r\n",
    "    test_set_size = []\r\n",
    "    \r\n",
    "    for batch in tqdm(loader):\r\n",
    "        input_ids = torch.cat([i.reshape(1,-1) for i in batch['input_ids']], dim=0).to(device)\r\n",
    "        attention_mask = torch.cat([i.reshape(1,-1) for i in batch['attention_mask']], dim=0).to(device)\r\n",
    "        label = batch['label'].to(device)\r\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\r\n",
    "        preds = logits.argmax(-1)\r\n",
    "        \r\n",
    "        tmp_test_size = [nor2len_dict[train_mid2label_dict[label_id.item()]]  for label_id in label]\r\n",
    "        test_set_size = test_set_size + tmp_test_size\r\n",
    "        \r\n",
    "        true.append(label.to(torch.device('cpu')))\r\n",
    "        pred.append(preds[:len(label)].to(torch.device('cpu')))\r\n",
    "\r\n",
    "    pred = torch.cat(pred).numpy()\r\n",
    "    true = torch.cat(true).numpy()    \r\n",
    "    \r\n",
    "    test_set_size = np.array(test_set_size)\r\n",
    "    acc, precision, recall, f1= report(true, pred)\r\n",
    "    overall = {\r\n",
    "        'accuracy': acc,\r\n",
    "        'f1': f1,\r\n",
    "        'precision': precision,\r\n",
    "        'recall': recall\r\n",
    "    }\r\n",
    "    high, middle, few = calc_split(5, 20, true, pred, test_set_size)\r\n",
    "    part = {\r\n",
    "        'high':{\r\n",
    "            'accuracy': high[0],\r\n",
    "            'precision': high[1],\r\n",
    "            'recall': high[2],\r\n",
    "            'f1': high[3],\r\n",
    "        },\r\n",
    "        'middle':{\r\n",
    "            'accuracy': middle[0],\r\n",
    "            'precision': middle[1],\r\n",
    "            'recall': middle[2],\r\n",
    "            'f1': middle[3],\r\n",
    "        }, \r\n",
    "        'few':{\r\n",
    "            'accuracy': few[0],\r\n",
    "            'precision': few[1],\r\n",
    "            'recall': few[2],\r\n",
    "            'f1': few[3],\r\n",
    "        },     \r\n",
    "    }\r\n",
    "    return (overall, part)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "dev_overall, dev_part = evaluate(model, dev_dataset, nor2len_dict, train_mid2label_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 426/426 [01:13<00:00,  5.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 85.308%\n",
      "Macro Avg Precision: 66.874%\n",
      "Macro Avg Recall: 69.666%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jxqi/anaconda3/envs/nlp_test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jxqi/anaconda3/envs/nlp_test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Macro Avg F1_score: 67.547%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(dev_overall)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'accuracy': 85.30832675104246, 'f1': 68.01655447424996, 'precision': 67.33860369578946, 'recall': 70.15044163355083}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from pprint import pprint\r\n",
    "\r\n",
    "pprint(dev_part)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'few': {'accuracy': 42.969334330590875,\n",
      "         'f1': 42.87317620650954,\n",
      "         'precision': 42.83576505798728,\n",
      "         'recall': 42.96670407781519},\n",
      " 'high': {'accuracy': 89.91820306413918,\n",
      "          'f1': 82.08666408399763,\n",
      "          'precision': 82.57111870924956,\n",
      "          'recall': 83.31117209166113},\n",
      " 'middle': {'accuracy': 67.33297316765712,\n",
      "            'f1': 67.00544742318522,\n",
      "            'precision': 66.96229648671807,\n",
      "            'recall': 67.31852123882973}}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_overall, test_part = evaluate(model, test_dataset, nor2len_dict, train_mid2label_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 455/455 [01:20<00:00,  5.66it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(test_overall)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'accuracy': 83.30295422498882, 'f1': 62.793747052625946, 'precision': 61.73278962939942, 'recall': 65.47052312326386}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from pprint import pprint\r\n",
    "\r\n",
    "pprint(test_part)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'few': {'accuracy': 40.99082568807339,\n",
      "         'f1': 40.75298438934802,\n",
      "         'precision': 40.615243342516074,\n",
      "         'recall': 41.02846648301194},\n",
      " 'high': {'accuracy': 90.01760227345027,\n",
      "          'f1': 82.09937202259643,\n",
      "          'precision': 82.33997433157705,\n",
      "          'recall': 83.43299147360005},\n",
      " 'middle': {'accuracy': 67.80760223383174,\n",
      "            'f1': 67.55539233688333,\n",
      "            'precision': 67.5174439955931,\n",
      "            'recall': 67.83266005631044}}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}